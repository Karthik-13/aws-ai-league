â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  QUICK REFERENCE CARD                                     â•‘
â•‘            LLM Fine-tuning Dataset Generation                            â•‘
â•‘                    (LangChain Implementation)                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš¡ QUICK START
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# Install dependencies
pip install -r requirements_langchain.txt

# Configure AWS
aws configure

# Run complete pipeline using config.yaml (recommended)
cd agents
python langchain_pipeline.py --config config.yaml

# Run complete pipeline with CLI arguments
python agents/langchain_pipeline.py "your topic" --num-questions 100

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ COMMON COMMANDS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USING CONFIG.YAML (RECOMMENDED):
  cd agents
  python langchain_pipeline.py --config config.yaml
  python langchain_question_generator.py --config config.yaml
  python langchain_question_deduplicator.py --config config.yaml
  python langchain_response_generator.py --config config.yaml
  python langchain_response_improver.py --config config.yaml

WITH CLI ARGUMENTS:
  python agents/langchain_pipeline.py "topic" --num-questions 500

WITH CATEGORIES:
  python agents/langchain_pipeline.py "topic" -n 1000 \
    --categories "cat1,cat2,cat3"

CUSTOM PROMPTS:
  python agents/langchain_pipeline.py "topic" -n 300 \
    --question-system-prompt "Generate X questions" \
    --response-system-prompt "Provide Y answers"

NO CONTEXT (FASTER):
  python agents/langchain_pipeline.py "topic" -n 500 --no-context

PARALLEL PROCESSING:
  python agents/langchain_response_generator.py questions.jsonl \
    --max-workers 3

RESUME FROM INTERRUPTION:
  python agents/langchain_response_generator.py questions.jsonl \
    --resume-from output/training_data_partial.jsonl

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”§ INDIVIDUAL AGENTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

QUESTION GENERATOR:
  python agents/langchain_question_generator.py "topic" -n 1000

DEDUPLICATOR:
  python agents/langchain_question_deduplicator.py questions.jsonl

RESPONSE GENERATOR:
  python agents/langchain_response_generator.py questions_deduplicated.jsonl

RESPONSE IMPROVER (OPTIONAL):
  python agents/langchain_response_improver.py training_data.jsonl

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š PARAMETERS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

QUESTION GENERATOR:
  --num-questions, -n      Number to generate (default: 100)
  --batch-size, -b         Questions per batch (default: 20)
  --temperature            Diversity 0.0-1.0 (default: 0.9)
  --categories, -c         Comma-separated categories
  --system-prompt, -s      Custom system prompt
  --resume-from, -r        Resume from existing file
  --config                 Path to config.yaml

DEDUPLICATOR:
  --threshold, -t          Similarity threshold (default: 0.85)
  --method, -m             'threshold' or 'clustering'
  --eps                    DBSCAN epsilon (default: 0.15)
  --config                 Path to config.yaml

RESPONSE GENERATOR:
  --chunk-size, -c         Questions per call (default: 5)
  --temperature            Creativity 0.0-1.0 (default: 0.7)
  --max-tokens             Max response length (default: 2048)
  --timeout                Request timeout seconds (default: 300)
  --max-workers            Parallel workers (default: 1)
  --no-context             Skip context generation
  --system-prompt, -s      Custom system prompt
  --resume-from, -r        Resume from partial file
  --config                 Path to config.yaml

RESPONSE IMPROVER:
  --chunk-size, -c         Examples per call (default: 5)
  --temperature            Lower for consistency (default: 0.3)
  --max-tokens             Max tokens per evaluation (default: 4096)
  --timeout                Request timeout seconds (default: 600)
  --max-workers            Parallel workers (default: 1)
  --fix-only               Only fix issues, don't improve good responses
  --config                 Path to config.yaml

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’° COST ESTIMATES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  100 questions:    ~$0.50
  500 questions:    ~$2.50
  1,000 questions:  ~$5.00
  5,000 questions:  ~$25.00

(With response improvement: add ~$2-3 per 1000 questions)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ OUTPUT FILES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

output/
  â”œâ”€â”€ questions_topic_timestamp.jsonl          # Generated questions
  â”œâ”€â”€ questions_topic_timestamp_stats.json     # Generation stats
  â”œâ”€â”€ questions_deduplicated_*.jsonl          # After deduplication
  â”œâ”€â”€ questions_deduplicated_*_stats.json     # Dedup stats
  â”œâ”€â”€ training_data_*.jsonl                   # FINAL OUTPUT âœ¨
  â”œâ”€â”€ training_data_*_stats.json              # Response stats
  â”œâ”€â”€ training_data_*_improved.jsonl          # Improved (optional)
  â””â”€â”€ training_data_*_improved_stats.json      # Improvement stats (optional)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ OUTPUT FORMAT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{"instruction": "question here", "context": "", "response": "answer here"}

Ready for LLM instruction fine-tuning!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš™ï¸  CONFIG.YAML
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

All agents automatically search for config.yaml in:
  1. Current directory
  2. agents/config.yaml
  3. Path specified by --config argument
  4. Environment variable AILEAGUE_CONFIG

Sections in config.yaml:
  - question:    Question generator settings
  - dedup:       Deduplicator settings
  - response:    Response generator settings
  - improver:    Response improver settings (optional)
  - pipeline:    Pipeline-specific overrides

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“– DOCUMENTATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

START HERE:
  â†’ README.md               Main documentation
  â†’ QUICKSTART.md           Get running in 30 seconds

DETAILED:
  â†’ README_LANGCHAIN.md     Detailed LangChain documentation
  â†’ ARCHITECTURE.md         System design
  â†’ COMPARISON.md           Implementation details

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ†˜ TROUBLESHOOTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"No credentials found"
  â†’ Run: aws configure

"Access denied"
  â†’ Enable Claude models in AWS Bedrock console
  â†’ Check IAM permissions
  â†’ Verify model ID (or use inference profile ARN)

"Read timeout"
  â†’ Increase --timeout to 600
  â†’ Reduce --chunk-size to 1
  â†’ Reduce --max-tokens

"Too many duplicates"
  â†’ Lower --dedup-threshold to 0.80
  â†’ Increase --question-temperature to 0.95
  â†’ Use categories to guide generation

"Import error"
  â†’ pip install -r requirements_langchain.txt
  â†’ Check Python version (3.8+)

"Config file not found"
  â†’ Agents auto-discover config.yaml
  â†’ Or specify with --config path/to/config.yaml

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ¨ EXAMPLE TOPICS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â€¢ "customer service for e-commerce"
â€¢ "Python programming help and debugging"
â€¢ "medical information for patients"
â€¢ "legal advice for small business"
â€¢ "financial planning and investment"
â€¢ "cooking recipes and techniques"
â€¢ "tech support troubleshooting"
â€¢ "educational math tutoring"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‰ THAT'S IT!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

You have everything needed to generate high-quality fine-tuning datasets!

1. Install dependencies
2. Configure AWS
3. Edit config.yaml or use CLI arguments
4. Run pipeline
5. Start fine-tuning!

For help: Read README.md or QUICKSTART.md

Happy fine-tuning! ğŸš€
