## Code Index

This document provides a high-level index of the codebase for quick navigation.

### Top-level structure
- `agents/`: LangChain-based agents for generating questions, deduplicating, and producing responses; complete dataset pipeline.
- `other-ai-generated-datasets/`: JSONL datasets generated by various AI models.
- Root: helper scripts and utilities for data processing.

### agents/
**Core Pipeline Files:**
- `langchain_pipeline.py`
  - Classes: `LangChainDatasetPipeline`
  - Entry points: `main()`
  - Purpose: Orchestrates the complete dataset generation pipeline

**Individual Agent Files:**
- `langchain_question_generator.py`
  - Classes: `Question (pydantic)`, `QuestionBatch (pydantic)`, `QuestionGenConfig`, `QuestionGenerationAgent`
  - Entry points: `main()`
  - Purpose: Generates diverse questions about a topic

- `langchain_question_deduplicator.py`
  - Classes: `DeduplicationConfig`, `QuestionDeduplicationAgent`
  - Entry points: `main()`
  - Purpose: Removes semantically similar questions using embeddings

- `langchain_response_generator.py`
  - Classes: `TrainingExample (pydantic)`, `TrainingBatch (pydantic)`, `ResponseGenConfig`, `ResponseGenerationAgent`
  - Entry points: `main()`
  - Purpose: Generates context and responses for questions

- `langchain_response_improver.py`
  - Classes: `ResponseImproverConfig`, `ResponseImprovementAgent`
  - Entry points: `main()`
  - Purpose: Evaluates and improves generated responses (optional)

**Configuration:**
- `config.yaml`: Unified YAML configuration for all agents
- `requirements_langchain.txt`: Python dependencies

**Documentation:**
- `README.md`: Main documentation with complete usage guide
- `QUICKSTART.md`: Quick start guide
- `README_LANGCHAIN.md`: Detailed LangChain-specific documentation
- `ARCHITECTURE.md`: System architecture and data flow
- `COMPARISON.md`: Implementation comparison details
- `INDEX_COMPLETE.md`: Complete package index
- `QUICK_REFERENCE.txt`: Command reference card

**Data Directories:**
- `final_datasets/`: Contains finalized JSONL datasets ready for use
- `output/`: Contains intermediate and final outputs from pipeline runs

### other-ai-generated-datasets/
Collection of JSONL datasets generated by various AI models and processing scripts:
- Datasets from Claude, Gemini, and other sources
- Various processed and intermediate dataset versions
- Sample and test datasets

### Root scripts
**Data Processing Utilities:**
- `keep-jsonl-keys.py`: Utility to filter/keep specific keys in JSONL files
  - Functions: `keep_only_keys`

- `rename_keys.py`: Utility to rename keys in JSONL files
  - Functions: `rename_keys`

- `parquet_to_jsonl.py`: Converts Parquet files to JSONL format
  - Functions: `parquet_to_jsonl`

- `partyrock-convert.py`: Conversion utility for PartyRock data format

**Other Files:**
- `questions.txt`: Sample questions file
- `CODE_INDEX.md`: This file

### Notes
- All agent scripts expose `main()` for CLI usage
- All agents support both YAML configuration (`config.yaml`) and command-line arguments
- The pipeline uses LangChain for type-safe, modular LLM interactions
- All outputs are in JSONL format suitable for LLM fine-tuning


